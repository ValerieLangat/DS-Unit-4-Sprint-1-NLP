{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['I','i','it','It','its',\"it's\",\n",
    "                                            'was','they', 'of','for',\n",
    "                                            'my','My','was', 'he','she',\n",
    "                                            'here','where','\\n','\\n\\n',\n",
    "                                            'the','we',\"i'm\",'&','they',\n",
    "                                            ' ','We',\"I'm\", \"I've\",'They',\n",
    "                                            'The','-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    tokens = []\n",
    "\n",
    "    for doc in tokenizer.pipe(yelp['text'], batch_size=500):\n",
    "\n",
    "        doc_tokens = []\n",
    "\n",
    "        for token in doc: \n",
    "            if token.text not in STOP_WORDS:\n",
    "                doc_tokens.append(token.text.lower())\n",
    "\n",
    "        tokens.append(doc_tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>[beware!!!, fake,, fake,, fake....we, small, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>[came, lunch, togo., service, quick., staff, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>[vegas, dozens, times, stepped, foot, circus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>[went, night, closed, street, party..., and, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>[3.5, 4, stars, not, bad, price,, $12.99, lunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tasty, fast casual Latin street food.  The men...</td>\n",
       "      <td>[tasty,, fast, casual, latin, street, food., m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This show is absolutely amazing!! What an incr...</td>\n",
       "      <td>[this, absolutely, amazing!!, what, incredible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Came for the Pho and really enjoyed it!  We go...</td>\n",
       "      <td>[came, pho, enjoyed, it!, got, 9:00pm, busy, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Absolutely the most Unique experience in a nai...</td>\n",
       "      <td>[absolutely, unique, experience, nail, shop, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wow. I walked in and sat at the bar for 10 min...</td>\n",
       "      <td>[wow., walked, sat, bar, 10, minutes., all, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We popped in for dinner yesterday with no rese...</td>\n",
       "      <td>[popped, dinner, yesterday, reservation,, desp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thw worst stay ever! So first i ended up payin...</td>\n",
       "      <td>[thw, worst, stay, ever!, so, ended, paying, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Great friendly customer service and quality fo...</td>\n",
       "      <td>[great, friendly, customer, service, quality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The food was great!  It was super busy but our...</td>\n",
       "      <td>[food, great!, super, busy, server, attentive....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Talk about getting ripped off. They charged us...</td>\n",
       "      <td>[talk, getting, ripped, off., charged, $420, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Girls night out tonight with my kid so we deci...</td>\n",
       "      <td>[girls, night, tonight, kid, decided, drive, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stopped in here for a few drinks flying out of...</td>\n",
       "      <td>[stopped, drinks, flying, charlotte, weeks, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This is an excellent restaurant and I encourag...</td>\n",
       "      <td>[this, excellent, restaurant, encourage, visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Had purchased a Groupon for a massage from Mar...</td>\n",
       "      <td>[had, purchased, groupon, massage, maryann, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BELOW is my previous review and it STILL STAND...</td>\n",
       "      <td>[below, previous, review, still, stands, 2, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Awesome AYCE sushi joint. I like that they mak...</td>\n",
       "      <td>[awesome, ayce, sushi, joint., like, fresh, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yorkdale Shopping Centre is the best mall in T...</td>\n",
       "      <td>[yorkdale, shopping, centre, best, mall, toron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bianco's is the best marketing ploy in the cit...</td>\n",
       "      <td>[bianco's, best, marketing, ploy, city,, power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Haven't had Indian food in a while but the buf...</td>\n",
       "      <td>[haven't, indian, food, buffet, legit, buffet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Their kids menu has Kraft Mac n Cheese. The pr...</td>\n",
       "      <td>[their, kids, menu, kraft, mac, n, cheese., pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>This place is friendly, clean (yes even the ba...</td>\n",
       "      <td>[this, place, friendly,, clean, (yes, bathroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Just about every high end retailer has a store...</td>\n",
       "      <td>[just, high, end, retailer, store, forum, shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>After spending 3 hours at Last Chance, my dad ...</td>\n",
       "      <td>[after, spending, 3, hours, last, chance,, dad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>First off if you love the feel of a throw back...</td>\n",
       "      <td>[first, love, feel, throw, joint, love, place!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Had been a long time since coming here. Glad I...</td>\n",
       "      <td>[had, long, time, coming, here., glad, finally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>A must know ---- EXPENSIVE\\n\\nI went here for ...</td>\n",
       "      <td>[a, know, ----, expensive, went, work, dinner....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>I'm only providing 5 stars for a service techn...</td>\n",
       "      <td>[providing, 5, stars, service, technician, nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>The couple who run this place can be seen firs...</td>\n",
       "      <td>[couple, run, place, seen, thing, morning, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>I've grabbed dinner to go here a couple times ...</td>\n",
       "      <td>[grabbed, dinner, couple, times, past, months....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>I had almost given up on finding a good Mexica...</td>\n",
       "      <td>[given, finding, good, mexican, restaurant, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>One word...AMAZING!!!\\nThe selections are out ...</td>\n",
       "      <td>[one, word...amazing!!!, selections, world, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>This is the whole package.? Great ambience, am...</td>\n",
       "      <td>[this, package.?, great, ambience,, amazing, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>I order a burger it was cold and no test at al...</td>\n",
       "      <td>[order, burger, cold, test, good, jack, daniel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>Love the Roxton. Solid service, lovely owners,...</td>\n",
       "      <td>[love, roxton., solid, service,, lovely, owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>Not impressed at all. This place came recommen...</td>\n",
       "      <td>[not, impressed, all., this, place, came, reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>Well I'm not to hard to please when I go to wa...</td>\n",
       "      <td>[well, hard, watch, sports, drink., but, went,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>As Authentic as it gets. Try the Kobe beef car...</td>\n",
       "      <td>[as, authentic, gets., try, kobe, beef, carpac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>Tried this place for the first time.. and I'm ...</td>\n",
       "      <td>[tried, place, time.., asking, wait, long., it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>Before going to 9037 Salon, I used to go to a ...</td>\n",
       "      <td>[before, going, 9037, salon,, barbershop, lagu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>Best bowl of dandan noodles I've ever had. Hug...</td>\n",
       "      <td>[best, bowl, dandan, noodles, had., huge, port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>I am truly touched by the customer service of ...</td>\n",
       "      <td>[truly, touched, customer, service, wildflower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>If you are looking for me I can save you a lit...</td>\n",
       "      <td>[if, looking, save, little, time., don't, both...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>SW was awesome! I got the chance to tour with ...</td>\n",
       "      <td>[sw, awesome!, got, chance, tour, diana, amazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Purchased my car here and am super happy overa...</td>\n",
       "      <td>[purchased, car, super, happy, overall., colea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>Indie has been a favourite of many Junctionite...</td>\n",
       "      <td>[indie, favourite, junctionites, opening, door...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Such a great little spot! It's been her since ...</td>\n",
       "      <td>[such, great, little, spot!, it's, remember, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>I have been going here for over 8 years, every...</td>\n",
       "      <td>[going, 8, years,, professional., services, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>This salon is under new management and the new...</td>\n",
       "      <td>[this, salon, new, management, new, owners, am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>Reading all the the reviews I am sure the Doct...</td>\n",
       "      <td>[reading, reviews, sure, doctor, professional,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Loga has expanded the menu to include parathas...</td>\n",
       "      <td>[loga, expanded, menu, include, parathas, beef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>My family and I were hungry and this Subway is...</td>\n",
       "      <td>[family, hungry, subway, open, 24, hours, guy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>My wife and I came here with a a couple of fri...</td>\n",
       "      <td>[wife, came, couple, friends., sever, excited,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>The food was just OK and not anything to brag ...</td>\n",
       "      <td>[food, ok, brag, about., food, hot,, items, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Today's visit is great!! Love and enjoy Town S...</td>\n",
       "      <td>[today's, visit, great!!, love, enjoy, town, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>This is the absolute worst place I have ever s...</td>\n",
       "      <td>[this, absolute, worst, place, stayed, 43, yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...   \n",
       "1     Came here for lunch Togo. Service was quick. S...   \n",
       "2     I've been to Vegas dozens of times and had nev...   \n",
       "3     We went here on a night where they closed off ...   \n",
       "4     3.5 to 4 stars\\n\\nNot bad for the price, $12.9...   \n",
       "5     Tasty, fast casual Latin street food.  The men...   \n",
       "6     This show is absolutely amazing!! What an incr...   \n",
       "7     Came for the Pho and really enjoyed it!  We go...   \n",
       "8     Absolutely the most Unique experience in a nai...   \n",
       "9     Wow. I walked in and sat at the bar for 10 min...   \n",
       "10    We popped in for dinner yesterday with no rese...   \n",
       "11    Thw worst stay ever! So first i ended up payin...   \n",
       "12    Great friendly customer service and quality fo...   \n",
       "13    The food was great!  It was super busy but our...   \n",
       "14    Talk about getting ripped off. They charged us...   \n",
       "15    Girls night out tonight with my kid so we deci...   \n",
       "16    Stopped in here for a few drinks flying out of...   \n",
       "17    This is an excellent restaurant and I encourag...   \n",
       "18    Had purchased a Groupon for a massage from Mar...   \n",
       "19    BELOW is my previous review and it STILL STAND...   \n",
       "20    Awesome AYCE sushi joint. I like that they mak...   \n",
       "21    Yorkdale Shopping Centre is the best mall in T...   \n",
       "22    Bianco's is the best marketing ploy in the cit...   \n",
       "23    Haven't had Indian food in a while but the buf...   \n",
       "24    Their kids menu has Kraft Mac n Cheese. The pr...   \n",
       "25    This place is friendly, clean (yes even the ba...   \n",
       "26    Just about every high end retailer has a store...   \n",
       "27    After spending 3 hours at Last Chance, my dad ...   \n",
       "28    First off if you love the feel of a throw back...   \n",
       "29    Had been a long time since coming here. Glad I...   \n",
       "...                                                 ...   \n",
       "9970  A must know ---- EXPENSIVE\\n\\nI went here for ...   \n",
       "9971  I'm only providing 5 stars for a service techn...   \n",
       "9972  The couple who run this place can be seen firs...   \n",
       "9973  I've grabbed dinner to go here a couple times ...   \n",
       "9974  I had almost given up on finding a good Mexica...   \n",
       "9975  One word...AMAZING!!!\\nThe selections are out ...   \n",
       "9976  This is the whole package.? Great ambience, am...   \n",
       "9977  I order a burger it was cold and no test at al...   \n",
       "9978  Love the Roxton. Solid service, lovely owners,...   \n",
       "9979  Not impressed at all. This place came recommen...   \n",
       "9980  Well I'm not to hard to please when I go to wa...   \n",
       "9981  As Authentic as it gets. Try the Kobe beef car...   \n",
       "9982  Tried this place for the first time.. and I'm ...   \n",
       "9983  Before going to 9037 Salon, I used to go to a ...   \n",
       "9984  Best bowl of dandan noodles I've ever had. Hug...   \n",
       "9985  I am truly touched by the customer service of ...   \n",
       "9986  If you are looking for me I can save you a lit...   \n",
       "9987  SW was awesome! I got the chance to tour with ...   \n",
       "9988  Purchased my car here and am super happy overa...   \n",
       "9989  Indie has been a favourite of many Junctionite...   \n",
       "9990  Such a great little spot! It's been her since ...   \n",
       "9991  I have been going here for over 8 years, every...   \n",
       "9992  This salon is under new management and the new...   \n",
       "9993  Reading all the the reviews I am sure the Doct...   \n",
       "9994  Loga has expanded the menu to include parathas...   \n",
       "9995  My family and I were hungry and this Subway is...   \n",
       "9996  My wife and I came here with a a couple of fri...   \n",
       "9997  The food was just OK and not anything to brag ...   \n",
       "9998  Today's visit is great!! Love and enjoy Town S...   \n",
       "9999  This is the absolute worst place I have ever s...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [beware!!!, fake,, fake,, fake....we, small, b...  \n",
       "1     [came, lunch, togo., service, quick., staff, f...  \n",
       "2     [vegas, dozens, times, stepped, foot, circus, ...  \n",
       "3     [went, night, closed, street, party..., and, b...  \n",
       "4     [3.5, 4, stars, not, bad, price,, $12.99, lunc...  \n",
       "5     [tasty,, fast, casual, latin, street, food., m...  \n",
       "6     [this, absolutely, amazing!!, what, incredible...  \n",
       "7     [came, pho, enjoyed, it!, got, 9:00pm, busy, g...  \n",
       "8     [absolutely, unique, experience, nail, shop, f...  \n",
       "9     [wow., walked, sat, bar, 10, minutes., all, ba...  \n",
       "10    [popped, dinner, yesterday, reservation,, desp...  \n",
       "11    [thw, worst, stay, ever!, so, ended, paying, 7...  \n",
       "12    [great, friendly, customer, service, quality, ...  \n",
       "13    [food, great!, super, busy, server, attentive....  \n",
       "14    [talk, getting, ripped, off., charged, $420, s...  \n",
       "15    [girls, night, tonight, kid, decided, drive, h...  \n",
       "16    [stopped, drinks, flying, charlotte, weeks, ba...  \n",
       "17    [this, excellent, restaurant, encourage, visit...  \n",
       "18    [had, purchased, groupon, massage, maryann, ma...  \n",
       "19    [below, previous, review, still, stands, 2, ye...  \n",
       "20    [awesome, ayce, sushi, joint., like, fresh, in...  \n",
       "21    [yorkdale, shopping, centre, best, mall, toron...  \n",
       "22    [bianco's, best, marketing, ploy, city,, power...  \n",
       "23    [haven't, indian, food, buffet, legit, buffet,...  \n",
       "24    [their, kids, menu, kraft, mac, n, cheese., pr...  \n",
       "25    [this, place, friendly,, clean, (yes, bathroom...  \n",
       "26    [just, high, end, retailer, store, forum, shop...  \n",
       "27    [after, spending, 3, hours, last, chance,, dad...  \n",
       "28    [first, love, feel, throw, joint, love, place!...  \n",
       "29    [had, long, time, coming, here., glad, finally...  \n",
       "...                                                 ...  \n",
       "9970  [a, know, ----, expensive, went, work, dinner....  \n",
       "9971  [providing, 5, stars, service, technician, nam...  \n",
       "9972  [couple, run, place, seen, thing, morning, pre...  \n",
       "9973  [grabbed, dinner, couple, times, past, months....  \n",
       "9974  [given, finding, good, mexican, restaurant, ve...  \n",
       "9975  [one, word...amazing!!!, selections, world, fa...  \n",
       "9976  [this, package.?, great, ambience,, amazing, l...  \n",
       "9977  [order, burger, cold, test, good, jack, daniel...  \n",
       "9978  [love, roxton., solid, service,, lovely, owner...  \n",
       "9979  [not, impressed, all., this, place, came, reco...  \n",
       "9980  [well, hard, watch, sports, drink., but, went,...  \n",
       "9981  [as, authentic, gets., try, kobe, beef, carpac...  \n",
       "9982  [tried, place, time.., asking, wait, long., it...  \n",
       "9983  [before, going, 9037, salon,, barbershop, lagu...  \n",
       "9984  [best, bowl, dandan, noodles, had., huge, port...  \n",
       "9985  [truly, touched, customer, service, wildflower...  \n",
       "9986  [if, looking, save, little, time., don't, both...  \n",
       "9987  [sw, awesome!, got, chance, tour, diana, amazi...  \n",
       "9988  [purchased, car, super, happy, overall., colea...  \n",
       "9989  [indie, favourite, junctionites, opening, door...  \n",
       "9990  [such, great, little, spot!, it's, remember, g...  \n",
       "9991  [going, 8, years,, professional., services, no...  \n",
       "9992  [this, salon, new, management, new, owners, am...  \n",
       "9993  [reading, reviews, sure, doctor, professional,...  \n",
       "9994  [loga, expanded, menu, include, parathas, beef...  \n",
       "9995  [family, hungry, subway, open, 24, hours, guy,...  \n",
       "9996  [wife, came, couple, friends., sever, excited,...  \n",
       "9997  [food, ok, brag, about., food, hot,, items, ta...  \n",
       "9998  [today's, visit, great!!, love, enjoy, town, s...  \n",
       "9999  [this, absolute, worst, place, stayed, 43, yea...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(yelp['text'])\n",
    "\n",
    "yelp['tokens'] = tokens\n",
    "\n",
    "yelp[['text', 'tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_rev = \"\"\"The food was absolutely delicious. The staff was kind and the service was fast. \n",
    "            You can tell that they take pride in maintaining a clean establishment and they play\n",
    "            great music! Definitely recommend!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(yelp['text'])\n",
    "reviews.append(fake_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        max_features = 5000, \n",
    "                        min_df=5)\n",
    "\n",
    "vect = tfidf.fit_transform(reviews)\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "nn.fit(vect.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Review 1\n",
      "天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用心製作，包含擺盤精緻、佐料衛生，夏日想開胃，這是一個不錯的選擇，服務人員也很敬業，以後會常常來 \n",
      "\n",
      "Similar Review 2\n",
      "旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\n",
      "質問にも丁寧に答えてくれましたし、日本人の方も日本語が話せる方も居て、とても綺麗で居心地のいいお店でした。 \n",
      "ネイルはちはるさんと言う綺麗な方が丁寧にしてくれとても気に入りました。\n",
      "予定になかったまつ毛エクステもお願いし、 \n",
      "\n",
      "Similar Review 3\n",
      "The food was delicious.  The music they play is like fingernails scraping against a chalkboard to my ears.  I don't think that I will be back. \n",
      "\n",
      "Similar Review 4\n",
      "Bryce amazing blowout and Talaya great make up! It's a must come back to! I'll be back again for sure. Clean establishment and friendly staff. \n",
      "\n",
      "Similar Review 5\n",
      "My first visit Nick was very helpful. I love the location of this Music Academy. Susan Diane is a Great vocal coach. My daughter loves this place! I w \n",
      "\n",
      "Similar Review 6\n",
      "Friendly staff, great music and absolutely Best watermelon margaritas by the bartender, Nancy!!!!!!!! \n",
      "\n",
      "Similar Review 7\n",
      "Food is cheap and delicious, great quality. I would recommend for anyone looking for a delicious ramen spot. Fast service, polite and attentive server \n",
      "\n",
      "Similar Review 8\n",
      "No review could tell you how much OTA services and staff get! Clean store front, well organized and awesome selection of supreme tees and hoodies! Sam \n",
      "\n",
      "Similar Review 9\n",
      "Absolutely amazing. I highly recommend anyone trying this place they are delicious! Their staff is friendly and their atmosphere is very inviting \n",
      "\n",
      "Similar Review 10\n",
      "Good play area, seems fairly clean as far as indoor play areas go, with clean family bathrooms right by the play area.  What I like about THIS McDonal \n",
      "\n"
     ]
    }
   ],
   "source": [
    "closest_revs = nn.kneighbors(vect.todense()[10000], n_neighbors=11)\n",
    "\n",
    "for i in np.arange(1,11):\n",
    "    r_index = closest_revs[1][0][i]\n",
    "    print('Similar Review',i)\n",
    "    print(yelp['text'][r_index][:150],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\LambdaDS\\envs\\NLP_unit4\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', sgdc)])\n",
    "\n",
    "pipe.fit(yelp['text'], yelp['stars'])\n",
    "\n",
    "#predicts a 5 star rating for fake review\n",
    "pipe.predict([fake_rev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   44.9s finished\n",
      "C:\\LambdaDS\\envs\\NLP_unit4\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'clf__max_iter': (20, 10, 100)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'clf__max_iter':(20, 10, 100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6095 \n",
      "\n",
      "Estimator: Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "...m_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', grid_search.best_score_,'\\n')\n",
    "\n",
    "print('Estimator:', grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\LambdaDS\\envs\\NLP_unit4\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['place', 'best', 'pretty', 'good', 'service', 'got', 'food', 'good.', 'recommend', 'bar']\n",
      "pretty good service\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(reviews):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for r in reviews: \n",
    "        \n",
    "        tokens = tokenize(str(reviews))\n",
    "        data.append(tokens)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gather_data(yelp['tokens'])\n",
    "\n",
    "id2word = corpora.Dictionary(data)\n",
    "\n",
    "id2word.filter_extremes(no_below=5, no_above=0.90)\n",
    "\n",
    "corpus = [id2word.doc2bow(review) for review in data]\n",
    "\n",
    "len(corpus[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                  id2word=id2word,\n",
    "                  random_state=42,\n",
    "                  num_topics=10,\n",
    "                  workers=4\n",
    "                  )\n",
    "\n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n",
    "\n",
    "topics = [' '.join(t[:3]) for t in words]\n",
    "\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
    "  return pd.concat([default_term_info] + list(topic_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]\n",
    "\n",
    "def update(doc):\n",
    "    d_dist = {k:0 for k in range(0,3)}\n",
    "    for t in doc:\n",
    "        d_dist[t[0]] = t[1]\n",
    "    return d_dist\n",
    "\n",
    "new_distro = [update(d) for d in distro]\n",
    "\n",
    "df_distro = pd.DataFrame.from_records(new_distro)\n",
    "df_distro.columns = topics\n",
    "df_distro['stars'] = yelp['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distro.groupby('stars').mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "The results of the topic model seem to make sense. As someone who sometimes uses Yelp, I tend to leave reviews\n",
    "in cases of the extreme: I was either extremely pleased or extremely upset. More often than not, I tend to be \n",
    "really happy with the service when I visit an establishment. I expected reviews to trend similarly, which they\n",
    "did. I'm also sure that businesses that continue to receive harsh critisism either won't be in business long or \n",
    "struggle to gain enough customers to warrant sizable Yelp reviews which could also be a reason that many of the\n",
    "reviews are super positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
